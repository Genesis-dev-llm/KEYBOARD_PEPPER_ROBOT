# Pepper VR Teleoperation System

**Control a Pepper robot in real-time using Meta Quest 2 VR headset**

## 🎯 Project Overview

This system allows you to teleoperate a SoftBank Robotics Pepper robot through a Meta Quest 2 VR headset. Control Pepper's arms, head, hands, and base movement using intuitive VR controllers, with live camera feed streamed back to the headset.

### Key Features
- ✅ Real-time arm mimicry using inverse kinematics
- ✅ Base movement with joystick controls
- ✅ Head tracking synchronized to VR headset
- ✅ Hand open/close with trigger controls
- ✅ Live camera feed from Pepper to VR
- ✅ Pre-programmed motions (wave, dance)
- ✅ Emergency stop safety system
- ✅ Low-latency WebSocket communication

---

## 📋 Requirements

### Hardware
- **Pepper Robot** (NAOqi 2.5+)
- **Meta Quest 2** VR Headset
- **PC** running Windows/Linux/Mac with:
  - Python 3.8-3.11
  - Unity 2021.3+ with OpenXR
  - WiFi connection to Pepper

### Software Dependencies

#### Python (Backend)
```bash
pip install -r Python/requirements.txt
```
- qi==3.1.5 (Pepper communication)
- websockets==13.0 (Unity connection)
- Flask==3.1.2 (video streaming)
- opencv-python==4.12.0.88 (image processing)
- pynput==1.7.6 (keyboard testing)

#### Unity (Frontend)
- Unity 2021.3 LTS or newer
- OpenXR Plugin
- XR Interaction Toolkit
- NativeWebSocket package

---

## 🚀 Quick Start

### Step 1: Setup Python Environment

```bash
# Clone the repository
cd ~/Desktop/VR_PEPPER_ROBOT

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r Python/requirements.txt
```

### Step 2: Find Pepper's IP Address

Press Pepper's chest button once - it will announce its IP address verbally.

Example: `192.168.1.100`

### Step 3: Test Connection (IMPORTANT - Do This First!)

```bash
# Test basic connectivity
python test_qi_connection.py

# Test with keyboard controls (recommended before VR)
python test_keyboard_control.py 192.168.1.100
```

**Keyboard Test Controls:**
- Arrow keys: Move base
- Q/E: Rotate
- W/A/S/D: Head control
- U/I/J/K: Arm control
- [/]/;/': Hand control
- 1: Wave animation
- P: Print status
- ESC: Emergency stop

### Step 4: Start the Server

```bash
python Python/main.py --ip 192.168.1.100
```

You should see:
```
✓ Successfully connected to Pepper via qi framework
✓ Stiffness set to 1.0
✓ Moving to Stand posture
🤖 Robot is ready for teleoperation
✓ Starting command server on WebSocket port 5000...
Starting video streaming server on http://0.0.0.0:8080/video_feed
```

### Step 5: Configure Unity

1. Open Unity project
2. Navigate to `Assets/Scripts/Core/PepperConnection.cs`
3. Update `serverIp` to your PC's IP address (not Pepper's!)
   ```csharp
   public string serverIp = "192.168.1.101"; // Your PC's IP
   ```
4. Build and deploy to Quest 2

### Step 6: Use VR Controls

**Movement:**
- Left joystick: Move Pepper forward/back/strafe
- Right joystick (X-axis): Rotate Pepper

**Arms:**
- Grip button: Enable arm mimicry (hold to control)
- Release grip: Return arm to idle

**Hands:**
- Trigger: Close hand (0 = open, full press = closed)

**Head:**
- Your head rotation: Pepper mimics (automatic)

---

## 📁 Project Structure

```
VR_PEPPER_ROBOT/
├── Python/                          # Backend server
│   ├── main.py                      # Entry point
│   ├── network/
│   │   ├── command_receiver.py      # WebSocket server
│   │   └── video_streamer.py        # Camera streaming
│   ├── pepper_control/
│   │   ├── pepper_controller.py     # Main controller (qi)
│   │   ├── arm_controller.py        # Arm movements
│   │   ├── base_controller.py       # Base/wheel movements
│   │   ├── head_controller.py       # Head movements
│   │   ├── hand_controller.py       # Hand open/close
│   │   └── pre_motions.py           # Pre-programmed animations
│   ├── utils/
│   │   └── joint_limits.py          # Safety limits
│   └── requirements.txt             # Python dependencies
├── Config/
│   └── pepper_joint_limits.json     # Robot joint constraints
├── Unity/                           # VR Frontend
│   └── Assets/Scripts/
│       ├── Core/
│       │   ├── PepperConnection.cs  # WebSocket client
│       │   └── VRInputManager.cs    # Quest 2 input
│       ├── Controls/
│       │   ├── ArmIKController.cs   # IK solver & arm control
│       │   ├── BaseMovementController.cs
│       │   ├── HandController.cs
│       │   └── HeadController.cs
│       └── Utils/
│           └── IKSolver.cs          # Inverse kinematics
├── test_qi_connection.py            # Connection test script
├── test_keyboard_control.py         # Manual control tester
├── CONVERSION_GUIDE.md              # naoqi→qi migration guide
└── README.md                        # This file
```

---

## 🔧 Architecture

```
┌─────────────────────────────────────────────────┐
│           Meta Quest 2 VR Headset               │
│  ┌──────────────────────────────────────────┐  │
│  │  Unity VR App                            │  │
│  │  - Input Manager (controllers/headset)   │  │
│  │  - IK Solver (arm mimicry)               │  │
│  │  - Camera display (Pepper POV)           │  │
│  └─────────────┬────────────────────────────┘  │
└────────────────┼───────────────────────────────┘
                 │ WebSocket (Commands)
                 ▼
┌────────────────────────────────────────────────┐
│            PC/Laptop (Python Server)            │
│  ┌──────────────────────────────────────────┐  │
│  │  Command Receiver (WebSocket)            │  │
│  │         ▼                                 │  │
│  │  Pepper Controller (qi framework)        │  │
│  │  ├─ Arm Controller                       │  │
│  │  ├─ Base Controller                      │  │
│  │  ├─ Head Controller                      │  │
│  │  ├─ Hand Controller                      │  │
│  │  └─ Pre-motion Player                    │  │
│  └──────────────────────────────────────────┘  │
│  ┌──────────────────────────────────────────┐  │
│  │  Video Streamer (Flask HTTP)             │  │
│  └─────────────┬────────────────────────────┘  │
└────────────────┼───────────────────────────────┘
                 │ TCP/IP (qi protocol)
                 │ HTTP (video stream)
                 ▼
┌────────────────────────────────────────────────┐
│              Pepper Robot                       │
│  - NAOqi Services (ALMotion, ALVideoDevice)    │
│  - Camera, Arms, Base, Head, Hands             │
└────────────────────────────────────────────────┘
```

---

## 🐛 Troubleshooting

### Connection Issues

**"No route to host" error:**
```bash
# 1. Check Pepper is on
ping 192.168.1.100

# 2. Verify port is open
nc -zv 192.168.1.100 9559

# 3. Ensure same network
ip addr  # Check your IP
# Should be same subnet as Pepper (e.g., both 192.168.1.x)
```

**"qi import failed":**
```bash
pip uninstall qi
pip install qi==3.1.5
python -c "import qi; print('qi version:', qi.__version__)"
```

**Unity can't connect:**
- Make sure Python server is running FIRST
- Check firewall isn't blocking port 5000
- Verify you used your PC's IP, not Pepper's IP
- Try: `telnet YOUR_PC_IP 5000`

### Robot Behavior Issues

**Pepper not moving:**
- Check stiffness: Should see "Stiffness set to 1.0" in logs
- Autonomous Life might be active: Press chest button to disable
- Check joint limits in `Config/pepper_joint_limits.json`

**Arms moving erratically:**
- Increase `smoothingFactor` in `ArmIKController.cs`
- Check IK solver arm lengths match Pepper's dimensions
- Verify coordinate transformation settings

**Video feed not working:**
- Check Flask server is running (should see port 8080 message)
- Try accessing directly: `http://YOUR_PC_IP:8080/video_feed`
- Verify camera_id (0=top camera, 1=bottom camera)

### Performance Issues

**High latency:**
- Ensure all devices on same LAN (not WiFi to different routers)
- Reduce video resolution in `video_streamer.py`
- Increase `smoothingFactor` to reduce command frequency

**Robot lagging:**
- Check `movementSpeed` values aren't too high
- Monitor network bandwidth
- Reduce VR application frame rate if needed

---

## 🔐 Safety Features

1. **Joint Limits:** All movements clamped to safe ranges
2. **Emergency Stop:** Triggered on disconnect or ESC key
3. **Stiffness Control:** Can disable motors quickly
4. **Command Validation:** Malformed commands are rejected
5. **Pre-motion Lock:** VR controls disabled during animations

---

## 📊 Testing Checklist

Before each session:
- [ ] Pepper battery > 30%
- [ ] Pepper on stable surface
- [ ] Clear area around robot
- [ ] Python server connected successfully
- [ ] Keyboard test passes
- [ ] Video feed visible
- [ ] Emergency stop tested
- [ ] VR controllers tracked properly

---

## 🚧 Known Limitations

- Camera feed is mono (not stereo 3D)
- Pre-motions are hardcoded (not dynamically loadable)
- No force feedback in VR controllers
- IK solver is 5-DOF (no full 6-DOF hand orientation)
- Maximum ~20 commands/second due to NAOqi limits

---

## 🔮 Future Enhancements

- [ ] Implement dance and other pre-motions
- [ ] Add VR HUD with status display
- [ ] Hand tracking (replace controllers)
- [ ] Multi-camera stereo vision
- [ ] Record and replay motion sequences
- [ ] Autonomous navigation waypoints
- [ ] Voice command integration
- [ ] NAO robot synchronization

---

## 📝 License

This project is for educational and research purposes. Pepper and NAOqi are trademarks of SoftBank Robotics.

---

## 🤝 Contributing

Contributions welcome! Please test thoroughly before submitting PRs.

---

## 📧 Support

For issues:
1. Check troubleshooting section
2. Review logs in Python console
3. Test with keyboard controller first
4. Verify network connectivity

---

## 🎓 Credits

Developed for VR-based robot teleoperation research.
Built with qi framework, Unity, and Meta Quest 2.

**Last Updated:** October 2025
**Version:** 1.0.0 (qi migration complete)